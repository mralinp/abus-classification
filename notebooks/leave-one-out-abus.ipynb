{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LOADING THE DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "signature_data = []\n",
    "with open(\"./data/abus/signature.pkl\", \"rb\") as sig_file:\n",
    "    signature_data = pickle.load(sig_file)\n",
    "    \n",
    "for i in range(len(signature_data)):\n",
    "    x, y = signature_data[i]\n",
    "    y=np.array(y, dtype=np.float32)\n",
    "    x = torch.tensor(x)\n",
    "    y = torch.tensor(y).unsqueeze(0)\n",
    "    signature_data[i] = (x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([40, 360]) torch.Size([1])\n"
     ]
    }
   ],
   "source": [
    "x,y = signature_data[0]\n",
    "\n",
    "print(x.shape, y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60\n"
     ]
    }
   ],
   "source": [
    "normalized_signature = []\n",
    "\n",
    "for sample in signature_data:    \n",
    "    x, y = sample\n",
    "    for i in range(40):\n",
    "        s = x[i,:]    \n",
    "        if s.max() != 0:\n",
    "            s = (torch.abs(s - torch.mean(s)))/torch.sqrt(torch.var(s))\n",
    "        x[i,:] = s\n",
    "        \n",
    "    normalized_signature.append((x,y))\n",
    "\n",
    "print(len(normalized_signature))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.3452, 1.3452, 1.3452,  ..., 1.3452, 1.3452, 1.3452],\n",
      "        [0.9370, 0.9370, 0.9370,  ..., 0.9370, 0.9370, 0.9370],\n",
      "        [0.9113, 0.9113, 0.9113,  ..., 0.9113, 0.9113, 0.9113],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]])\n"
     ]
    }
   ],
   "source": [
    "x,y = normalized_signature[0]\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SequenceClassifier(torch.nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, num_classes, device='cpu'):\n",
    "        super(SequenceClassifier, self).__init__()\n",
    "        self.device = device\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.lstm = torch.nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.fc = torch.nn.Linear(hidden_size * 40, num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Set initial hidden and cell states\n",
    "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(self.device)\n",
    "        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(self.device)\n",
    "\n",
    "        # Forward propagate LSTM\n",
    "        out, _ = self.lstm(\n",
    "            x, (h0, c0)\n",
    "        )  # out: tensor of shape (batch_size, seq_length, hidden_size)\n",
    "        out = out.reshape(out.shape[0], -1)\n",
    "\n",
    "        # Decode the hidden state of the last time step\n",
    "        out = self.fc(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 30\n",
    "learning_rate = 10e-4\n",
    "device = 'cuda'\n",
    "criterion = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8bdae0656ff6474c872b5723641bcb15",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/60 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_147537/704394107.py:19: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  predictions = torch.nn.functional.softmax(predictions)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing sample #0: train acc is: 59.0/59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_147537/704394107.py:39: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  predictions = torch.nn.functional.softmax(predictions)\n",
      "/tmp/ipykernel_147537/704394107.py:57: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  predictions = torch.nn.functional.softmax(predictions)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing sample #1: train acc is: 59.0/59\n",
      "Testing sample #2: train acc is: 56.0/59\n",
      "Testing sample #3: train acc is: 54.0/59\n",
      "Testing sample #4: train acc is: 56.0/59\n",
      "Testing sample #5: train acc is: 52.0/59\n",
      "Testing sample #6: train acc is: 59.0/59\n",
      "Testing sample #7: train acc is: 58.0/59\n",
      "Testing sample #8: train acc is: 59.0/59\n",
      "Testing sample #9: train acc is: 59.0/59\n",
      "Testing sample #10: train acc is: 59.0/59\n",
      "Testing sample #11: train acc is: 55.0/59\n",
      "Testing sample #12: train acc is: 59.0/59\n"
     ]
    }
   ],
   "source": [
    "signature_data = normalized_signature\n",
    "num_correct_predictions = 0\n",
    "num_samples = len(signature_data)\n",
    "main_loop = tqdm(range(len(signature_data)))\n",
    "for idx in main_loop:\n",
    "    train_data = signature_data[:idx] + signature_data[idx+1:]\n",
    "    model = SequenceClassifier(360, 40, 1, 2, device=device).to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate) \n",
    "    test_sample = signature_data[idx]\n",
    "    train_loader = torch.utils.data.DataLoader(train_data, batch_size=4, num_workers=8, shuffle=True, pin_memory=True)\n",
    "    for epoch in range(num_epochs):\n",
    "        for data in train_loader:\n",
    "            \n",
    "            x, y = data\n",
    "            x = x.to(device).squeeze(1)\n",
    "            y = y.to(device).squeeze(1).long()  \n",
    "                    \n",
    "            predictions = model(x)\n",
    "            predictions = torch.nn.functional.softmax(predictions)\n",
    "            loss = criterion(predictions, y)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "                \n",
    "        total = 0\n",
    "        num_corrects = 0\n",
    "       \n",
    "    for data in train_loader:\n",
    "        \n",
    "        x, y = data\n",
    "        x = x.to(device).squeeze(1)\n",
    "        y = y.to(device).squeeze(1).long()\n",
    "        model.eval()\n",
    "        \n",
    "        with torch.no_grad():\n",
    "        \n",
    "            predictions = model(x)\n",
    "            predictions = torch.nn.functional.softmax(predictions)\n",
    "            _, predictions = predictions.max(1)\n",
    "            num_corrects += (predictions == y).float().sum()\n",
    "            total += predictions.size(0)\n",
    "        \n",
    "        model.train()\n",
    "    \n",
    "    print(f\"Testing sample #{idx}: train acc is: {num_corrects}/{total}\")\n",
    "                        \n",
    "    x, y = test_sample\n",
    "    x = x.to(device).unsqueeze(0)\n",
    "    y = y.to(device).unsqueeze(0).long()  \n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "\n",
    "        predictions = model(x)\n",
    "        predictions = torch.nn.functional.softmax(predictions)\n",
    "        _, predictions = predictions.max(1)\n",
    "        num_correct_predictions += (predictions == y).float().sum()\n",
    "        \n",
    "    model.train()\n",
    "    main_loop.set_postfix(test_accuracy=(num_correct_predictions).item()) \n",
    "        \n",
    "print(f\"Finished: test acc is: {num_correct_predictions}/{num_samples}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

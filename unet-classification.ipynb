{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "import torch\n",
    "import datasets\n",
    "import albumentations as A\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from models import unet\n",
    "import torchvision\n",
    "from transformers import ToTensorTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_transforms = A.Compose(\n",
    "#         [\n",
    "#             # A.Rotate(limit=35, p=1.0),\n",
    "#             # A.HorizontalFlip(p=0.5),\n",
    "#             # A.VerticalFlip(p=0.1),\n",
    "#             A.Normalize(\n",
    "#                 mean=[0.0],\n",
    "#                 std=[1.0],\n",
    "#                 max_pixel_value=255.0,\n",
    "#             ),\n",
    "#         ],\n",
    "#     )\n",
    "\n",
    "# val_transforms = A.Compose(\n",
    "#     [\n",
    "#         A.Normalize(\n",
    "#             mean=[0.0],\n",
    "#             std=[1.0],\n",
    "#             max_pixel_value=255.0,\n",
    "#         ),\n",
    "#     ],\n",
    "# )\n",
    "\n",
    "to_tensor = ToTensorTransformer()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = datasets.tdsc.TDSC(path_to_dataset=\"./data/tdsc\", train=True)\n",
    "validation_dataset = datasets.tdsc.TDSC(path_to_dataset=\"./data/tdsc\", train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(128, 128, 15)\n"
     ]
    }
   ],
   "source": [
    "x,y,l = train_dataset[0]\n",
    "x = x - x*y*0.5\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f797daa43a0>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(x[:,:,7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(128, 128, 15) (128, 128, 15)\n",
      "torch.Size([15, 1, 128, 128])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(x.shape, y.shape)\n",
    "x,y = to_tensor((x,y))\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = unet.UNet(in_channels=1, out_channels=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dice loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DiceLoss(torch.nn.Module):\n",
    "    def __init__(self, smooth=1):\n",
    "        super(DiceLoss, self).__init__()\n",
    "        self.smooth = smooth\n",
    "\n",
    "    def forward(self, predictions, targets):\n",
    "        # Flatten predictions and targets\n",
    "        predictions = predictions.view(-1)\n",
    "        targets = targets.view(-1)\n",
    "\n",
    "        intersection = (predictions * targets).sum()\n",
    "        dice_coefficient = (2. * intersection + self.smooth) / (predictions.sum() + targets.sum() + self.smooth)\n",
    "\n",
    "        # The Dice Loss is the complement of the Dice Coefficient\n",
    "        dice_loss = 1 - dice_coefficient\n",
    "\n",
    "        return dice_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 1e-3\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "num_epochs = 20\n",
    "# criterion = DiceLoss()\n",
    "criterion = torch.nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "model = model.to(device=device)\n",
    "scaler = torch.cuda.amp.GradScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training model...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb80df0c8c4a4491881d2e3ee2413f4e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/80 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([15, 1, 128, 128]) torch.Size([15, 1, 128, 128]) torch.Size([15, 1, 128, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ozma/anaconda3/envs/torch/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "view size is not compatible with input tensor's size and stride (at least one dimension spans across two contiguous subspaces). Use .reshape(...) instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/home/ozma/Source/abus-classification/unet-classification.ipynb Cell 13\u001b[0m line \u001b[0;36m3\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/ozma/Source/abus-classification/unet-classification.ipynb#X14sZmlsZQ%3D%3D?line=26'>27</a>\u001b[0m         \u001b[39m# update tqdm loop\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/ozma/Source/abus-classification/unet-classification.ipynb#X14sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m         loop\u001b[39m.\u001b[39mset_postfix(loss\u001b[39m=\u001b[39mloss\u001b[39m.\u001b[39mitem())\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/ozma/Source/abus-classification/unet-classification.ipynb#X14sZmlsZQ%3D%3D?line=30'>31</a>\u001b[0m train(model, train_dataset, optimizer, criterion)\n",
      "\u001b[1;32m/home/ozma/Source/abus-classification/unet-classification.ipynb Cell 13\u001b[0m line \u001b[0;36m2\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/ozma/Source/abus-classification/unet-classification.ipynb#X14sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m     \u001b[39m# predictions = torch.sigmoid(predictions)\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/ozma/Source/abus-classification/unet-classification.ipynb#X14sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m     \u001b[39mprint\u001b[39m(predictions\u001b[39m.\u001b[39mshape, inputs\u001b[39m.\u001b[39mshape, targets\u001b[39m.\u001b[39mshape)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/ozma/Source/abus-classification/unet-classification.ipynb#X14sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m     loss \u001b[39m=\u001b[39m loss_fn(predictions, targets)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/ozma/Source/abus-classification/unet-classification.ipynb#X14sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m \u001b[39m# backward\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/ozma/Source/abus-classification/unet-classification.ipynb#X14sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m optimizer\u001b[39m.\u001b[39mzero_grad()\n",
      "File \u001b[0;32m~/anaconda3/envs/torch/lib/python3.9/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "\u001b[1;32m/home/ozma/Source/abus-classification/unet-classification.ipynb Cell 13\u001b[0m line \u001b[0;36m9\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/ozma/Source/abus-classification/unet-classification.ipynb#X14sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, predictions, targets):\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/ozma/Source/abus-classification/unet-classification.ipynb#X14sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m     \u001b[39m# Flatten predictions and targets\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/ozma/Source/abus-classification/unet-classification.ipynb#X14sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m     predictions \u001b[39m=\u001b[39m predictions\u001b[39m.\u001b[39mview(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/ozma/Source/abus-classification/unet-classification.ipynb#X14sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m     targets \u001b[39m=\u001b[39m targets\u001b[39m.\u001b[39;49mview(\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/ozma/Source/abus-classification/unet-classification.ipynb#X14sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m     intersection \u001b[39m=\u001b[39m (predictions \u001b[39m*\u001b[39m targets)\u001b[39m.\u001b[39msum()\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/ozma/Source/abus-classification/unet-classification.ipynb#X14sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m     dice_coefficient \u001b[39m=\u001b[39m (\u001b[39m2.\u001b[39m \u001b[39m*\u001b[39m intersection \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msmooth) \u001b[39m/\u001b[39m (predictions\u001b[39m.\u001b[39msum() \u001b[39m+\u001b[39m targets\u001b[39m.\u001b[39msum() \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msmooth)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: view size is not compatible with input tensor's size and stride (at least one dimension spans across two contiguous subspaces). Use .reshape(...) instead."
     ]
    }
   ],
   "source": [
    "def train(model, dataset, optimizer, loss_fn):\n",
    "    print(\"training model...\")\n",
    "    model.train()\n",
    "    loop = tqdm(dataset)\n",
    "    for data in loop:\n",
    "        x, y, l = data\n",
    "        # Make tumors obvious...\n",
    "        x = x - x*y*0.6\n",
    "        for i in range(0, x.shape[2], 32):\n",
    "            inputs = x[:,:,i:i+32]\n",
    "            targets = y[:,:,i:i+32]\n",
    "            # make the tumors obviously visible\n",
    "            inputs, targets = to_tensor((inputs, targets))\n",
    "            inputs = inputs.to(device)\n",
    "            targets = targets.to(device)            \n",
    "            # forward\n",
    "            with torch.cuda.amp.autocast():\n",
    "                predictions = model(inputs)\n",
    "                # predictions = torch.sigmoid(predictions)\n",
    "                print(predictions.shape, inputs.shape, targets.shape)\n",
    "                loss = loss_fn(predictions, targets)\n",
    "            # backward\n",
    "            optimizer.zero_grad()\n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "        # update tqdm loop\n",
    "        loop.set_postfix(loss=loss.item())\n",
    "\n",
    "\n",
    "train(model, train_dataset, optimizer, criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_accuracy(dataset, model, device=\"cuda\"):\n",
    "    \n",
    "    print(\"calculating model accuracy...\")\n",
    "\n",
    "    num_correct = 0\n",
    "    num_pixels = 0\n",
    "    dice_score = 0\n",
    "    \n",
    "    model.eval()\n",
    "    loop = tqdm(dataset)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for vol, mask, l in loop:\n",
    "            \n",
    "            # Make tumors obvious...\n",
    "            vol = vol-vol*mask\n",
    "            vol, mask = to_tensor((vol, mask))\n",
    "            \n",
    "            for i in range(0, vol.shape[2], 32):\n",
    "                x = vol[:,:,i:i+32]\n",
    "                y = mask[:,:,i:i+32]\n",
    "                x = x.to(device)\n",
    "                y = y.to(device)\n",
    "                preds = torch.sigmoid(model(x))\n",
    "                preds = (preds > 0.5).float()\n",
    "                num_correct += (preds == y).sum()\n",
    "                num_pixels += torch.numel(preds)\n",
    "                dice_score += (2 * (preds * y).sum()) / (\n",
    "                    (preds + y).sum() + 1e-8\n",
    "                )\n",
    "                \n",
    "            loop.set_postfix(dice_score=dice_score)\n",
    "\n",
    "    print(f\"Got {num_correct}/{num_pixels} with acc {num_correct/num_pixels*100:.2f}\")\n",
    "    print(f\"Dice score: {dice_score/len(dataset)}\")\n",
    "    \n",
    "    model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving the results as images...\n",
      "torch.Size([35, 1, 128, 128]) torch.Size([35, 1, 128, 128])\n"
     ]
    }
   ],
   "source": [
    "def save_results_as_imgs(model, dataset, path=\"./saved_images\"):\n",
    "    print(\"Saving the results as images...\")\n",
    "    model.eval()\n",
    "    idx = 0\n",
    "    vol, mask, label = dataset[idx]\n",
    "    vol = vol - vol*mask*0.6\n",
    "    vol, mask = to_tensor((vol, mask))\n",
    "    vol = vol.to(device)\n",
    "    mask = mask.to(device)\n",
    "    print(vol.shape, mask.shape)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        preds = torch.sigmoid(model(vol))\n",
    "        preds = (preds > 0.5).float()\n",
    "        torchvision.utils.save_image(preds, f\"{path}/prediction.png\")\n",
    "        torchvision.utils.save_image(mask, f\"{path}/ground_truth.png\")\n",
    "    model.train()\n",
    "    \n",
    "save_results_as_imgs(model, validation_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training model...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "49a5d8543cd74a4db89a269e9faf3e52",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/80 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving the results as images...\n",
      "torch.Size([15, 1, 128, 128]) torch.Size([15, 1, 128, 128])\n",
      "training model...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c8d791c9eea438e97cdad33ae3acf88",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/80 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving the results as images...\n",
      "torch.Size([15, 1, 128, 128]) torch.Size([15, 1, 128, 128])\n",
      "training model...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2accc160fb54621b44b985e79fd2b48",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/80 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/ozma/Source/abus-classification/unet-classification.ipynb Cell 16\u001b[0m line \u001b[0;36m2\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/ozma/Source/abus-classification/unet-classification.ipynb#X20sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(num_epochs):\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/ozma/Source/abus-classification/unet-classification.ipynb#X20sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m     train(model, train_dataset, optimizer, criterion)\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/ozma/Source/abus-classification/unet-classification.ipynb#X20sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m     \u001b[39m# calculate_accuracy(train_dataset, model)\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/ozma/Source/abus-classification/unet-classification.ipynb#X20sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     save_results_as_imgs(model, train_dataset)\n",
      "\u001b[1;32m/home/ozma/Source/abus-classification/unet-classification.ipynb Cell 16\u001b[0m line \u001b[0;36m5\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/ozma/Source/abus-classification/unet-classification.ipynb#X20sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m model\u001b[39m.\u001b[39mtrain()\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/ozma/Source/abus-classification/unet-classification.ipynb#X20sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m loop \u001b[39m=\u001b[39m tqdm(dataset)\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/ozma/Source/abus-classification/unet-classification.ipynb#X20sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39mfor\u001b[39;00m data \u001b[39min\u001b[39;00m loop:\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/ozma/Source/abus-classification/unet-classification.ipynb#X20sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     x, y, l \u001b[39m=\u001b[39m data\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/ozma/Source/abus-classification/unet-classification.ipynb#X20sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m     \u001b[39m# Make tumors obvious...\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/torch/lib/python3.9/site-packages/tqdm/notebook.py:254\u001b[0m, in \u001b[0;36mtqdm_notebook.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    252\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    253\u001b[0m     it \u001b[39m=\u001b[39m \u001b[39msuper\u001b[39m(tqdm_notebook, \u001b[39mself\u001b[39m)\u001b[39m.\u001b[39m\u001b[39m__iter__\u001b[39m()\n\u001b[0;32m--> 254\u001b[0m     \u001b[39mfor\u001b[39;00m obj \u001b[39min\u001b[39;00m it:\n\u001b[1;32m    255\u001b[0m         \u001b[39m# return super(tqdm...) will not catch exception\u001b[39;00m\n\u001b[1;32m    256\u001b[0m         \u001b[39myield\u001b[39;00m obj\n\u001b[1;32m    257\u001b[0m \u001b[39m# NB: except ... [ as ...] breaks IPython async KeyboardInterrupt\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/torch/lib/python3.9/site-packages/tqdm/std.py:1178\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1175\u001b[0m time \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_time\n\u001b[1;32m   1177\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1178\u001b[0m     \u001b[39mfor\u001b[39;00m obj \u001b[39min\u001b[39;00m iterable:\n\u001b[1;32m   1179\u001b[0m         \u001b[39myield\u001b[39;00m obj\n\u001b[1;32m   1180\u001b[0m         \u001b[39m# Update and possibly print the progressbar.\u001b[39;00m\n\u001b[1;32m   1181\u001b[0m         \u001b[39m# Note: does not call self.update(1) for speed optimisation.\u001b[39;00m\n",
      "File \u001b[0;32m~/Source/abus-classification/datasets/tdsc.py:50\u001b[0m, in \u001b[0;36mTDSC.__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m     46\u001b[0m mask_path \u001b[39m=\u001b[39m mask_path\u001b[39m.\u001b[39mreplace(\u001b[39m'\u001b[39m\u001b[39m\\\\\u001b[39;00m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39m/\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m     47\u001b[0m label \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m \u001b[39mif\u001b[39;00m label \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mM\u001b[39m\u001b[39m'\u001b[39m \u001b[39melse\u001b[39;00m \u001b[39m1\u001b[39m\n\u001b[0;32m---> 50\u001b[0m vol, _ \u001b[39m=\u001b[39m nrrd\u001b[39m.\u001b[39;49mread(\u001b[39mf\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m{\u001b[39;49;00m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpath_to_dataset\u001b[39m}\u001b[39;49;00m\u001b[39m/\u001b[39;49m\u001b[39m{\u001b[39;49;00mvol_path\u001b[39m}\u001b[39;49;00m\u001b[39m\"\u001b[39;49m)\n\u001b[1;32m     51\u001b[0m mask, _ \u001b[39m=\u001b[39m nrrd\u001b[39m.\u001b[39mread(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpath_to_dataset\u001b[39m}\u001b[39;00m\u001b[39m/\u001b[39m\u001b[39m{\u001b[39;00mmask_path\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m) \n\u001b[1;32m     53\u001b[0m \u001b[39m# # extracting tumors\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/torch/lib/python3.9/site-packages/nrrd/reader.py:517\u001b[0m, in \u001b[0;36mread\u001b[0;34m(filename, custom_field_map, index_order)\u001b[0m\n\u001b[1;32m    515\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39m(filename, \u001b[39m'\u001b[39m\u001b[39mrb\u001b[39m\u001b[39m'\u001b[39m) \u001b[39mas\u001b[39;00m fh:\n\u001b[1;32m    516\u001b[0m     header \u001b[39m=\u001b[39m read_header(fh, custom_field_map)\n\u001b[0;32m--> 517\u001b[0m     data \u001b[39m=\u001b[39m read_data(header, fh, filename, index_order)\n\u001b[1;32m    519\u001b[0m \u001b[39mreturn\u001b[39;00m data, header\n",
      "File \u001b[0;32m~/anaconda3/envs/torch/lib/python3.9/site-packages/nrrd/reader.py:446\u001b[0m, in \u001b[0;36mread_data\u001b[0;34m(header, fh, filename, index_order)\u001b[0m\n\u001b[1;32m    443\u001b[0m end_index \u001b[39m=\u001b[39m \u001b[39mmin\u001b[39m(start_index \u001b[39m+\u001b[39m _READ_CHUNKSIZE, compressed_data_len)\n\u001b[1;32m    445\u001b[0m \u001b[39m# Decompress and append data\u001b[39;00m\n\u001b[0;32m--> 446\u001b[0m decompressed_data \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m decompobj\u001b[39m.\u001b[39;49mdecompress(compressed_data[start_index:end_index])\n\u001b[1;32m    448\u001b[0m \u001b[39m# Update start index\u001b[39;00m\n\u001b[1;32m    449\u001b[0m start_index \u001b[39m=\u001b[39m end_index\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for i in range(num_epochs):\n",
    "    train(model, train_dataset, optimizer, criterion)\n",
    "    # calculate_accuracy(train_dataset, model)\n",
    "    save_results_as_imgs(model, train_dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([23, 1, 128, 128])\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 10 is out of bounds for dimension 1 with size 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/home/ozma/Source/abus-classification/unet-classification.ipynb Cell 16\u001b[0m line \u001b[0;36m6\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/ozma/Source/abus-classification/unet-classification.ipynb#X16sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m x, m \u001b[39m=\u001b[39m to_tensor((x,m))\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/ozma/Source/abus-classification/unet-classification.ipynb#X16sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39mprint\u001b[39m(x\u001b[39m.\u001b[39mshape)\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/ozma/Source/abus-classification/unet-classification.ipynb#X16sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m x \u001b[39m=\u001b[39m x[:,\u001b[39m10\u001b[39;49m,:,:]\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/ozma/Source/abus-classification/unet-classification.ipynb#X16sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39mprint\u001b[39m(x\u001b[39m.\u001b[39mshape)\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/ozma/Source/abus-classification/unet-classification.ipynb#X16sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m m \u001b[39m=\u001b[39m m[:,\u001b[39m10\u001b[39m,:,:]\n",
      "\u001b[0;31mIndexError\u001b[0m: index 10 is out of bounds for dimension 1 with size 1"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "\n",
    "x, m, y = validation_dataset[10]\n",
    "x, m = to_tensor((x,m))\n",
    "print(x.shape)\n",
    "x = x[:,10,:,:]\n",
    "print(x.shape)\n",
    "m = m[:,10,:,:]\n",
    "x = x.unsqueeze(0)\n",
    "print(x.shape)\n",
    "print(m.shape)\n",
    "x = x.to(device)\n",
    "prediction = torch.sigmoid(model(x))\n",
    "prediction = (prediction > 0.5).float()\n",
    "print (prediction.shape)\n",
    "pred = prediction.squeeze()\n",
    "m = m.squeeze()\n",
    "pred = pred.to('cpu').detach().numpy()\n",
    "m = m.to('cpu').detach().numpy()\n",
    "print (m.shape, pred.shape)\n",
    "plt.subplot(1,2,1)\n",
    "plt.imshow(pred)\n",
    "plt.subplot(1,2,2)\n",
    "plt.imshow(m)\n",
    "plt.show()\n",
    "\n",
    "model.train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "import pickle\n",
    "\n",
    "import utils.features.signature as signature\n",
    "import datasets\n",
    "import utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LOADING THE DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "signature_data = []\n",
    "with open(\"./data/tdsc/tumors/signature.pkl\", \"rb\") as sig_file:\n",
    "    signature_data = pickle.load(sig_file)\n",
    "    \n",
    "for i in range(len(signature_data)):\n",
    "    x, y = signature_data[i]\n",
    "    num_zero_slices = 180 - len(x)\n",
    "    zero_slices = [np.zeros(360, dtype=np.float32) for i in range(num_zero_slices)]\n",
    "    x = x + zero_slices\n",
    "    x=np.array(x, dtype=np.float32)\n",
    "    y=np.array(y, dtype=np.float32)\n",
    "    x = torch.tensor(x)\n",
    "    y = torch.tensor(y).unsqueeze(0)\n",
    "    signature_data[i] = (x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SequenceClassifier(torch.nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, num_classes, device='cpu'):\n",
    "        super(SequenceClassifier, self).__init__()\n",
    "        self.device = device\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.lstm = torch.nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.fc = torch.nn.Linear(hidden_size * 180, num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Set initial hidden and cell states\n",
    "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(self.device)\n",
    "        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(self.device)\n",
    "\n",
    "        # Forward propagate LSTM\n",
    "        out, _ = self.lstm(\n",
    "            x, (h0, c0)\n",
    "        )  # out: tensor of shape (batch_size, seq_length, hidden_size)\n",
    "\n",
    "        out = out.reshape(out.shape[0], -1)\n",
    "        \n",
    "        # Decode the hidden state of the last time step\n",
    "        out = self.fc(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 100\n",
    "learning_rate = 10e-4\n",
    "device = 'cuda'\n",
    "criterion = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8bf6f8e3c523449284627ef23e1e03ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing sample #0: train acc is: 83.0/99\n",
      "Testing sample #1: train acc is: 92.0/99\n",
      "Testing sample #2: train acc is: 85.0/99\n",
      "Testing sample #3: train acc is: 83.0/99\n",
      "Testing sample #4: train acc is: 96.0/99\n",
      "Testing sample #5: train acc is: 89.0/99\n",
      "Testing sample #6: train acc is: 83.0/99\n",
      "Testing sample #7: train acc is: 96.0/99\n",
      "Testing sample #8: train acc is: 86.0/99\n",
      "Testing sample #9: train acc is: 86.0/99\n",
      "Testing sample #10: train acc is: 81.0/99\n",
      "Testing sample #11: train acc is: 85.0/99\n",
      "Testing sample #12: train acc is: 84.0/99\n",
      "Testing sample #13: train acc is: 85.0/99\n",
      "Testing sample #14: train acc is: 83.0/99\n",
      "Testing sample #15: train acc is: 84.0/99\n",
      "Testing sample #16: train acc is: 83.0/99\n",
      "Testing sample #17: train acc is: 89.0/99\n",
      "Testing sample #18: train acc is: 86.0/99\n",
      "Testing sample #19: train acc is: 96.0/99\n",
      "Testing sample #20: train acc is: 87.0/99\n",
      "Testing sample #21: train acc is: 89.0/99\n",
      "Testing sample #22: train acc is: 89.0/99\n",
      "Testing sample #23: train acc is: 91.0/99\n",
      "Testing sample #24: train acc is: 85.0/99\n",
      "Testing sample #25: train acc is: 82.0/99\n",
      "Testing sample #26: train acc is: 86.0/99\n",
      "Testing sample #27: train acc is: 91.0/99\n",
      "Testing sample #28: train acc is: 84.0/99\n",
      "Testing sample #29: train acc is: 84.0/99\n",
      "Testing sample #30: train acc is: 86.0/99\n",
      "Testing sample #31: train acc is: 83.0/99\n",
      "Testing sample #32: train acc is: 87.0/99\n",
      "Testing sample #33: train acc is: 84.0/99\n",
      "Testing sample #34: train acc is: 86.0/99\n",
      "Testing sample #35: train acc is: 94.0/99\n",
      "Testing sample #36: train acc is: 89.0/99\n",
      "Testing sample #37: train acc is: 87.0/99\n",
      "Testing sample #38: train acc is: 87.0/99\n",
      "Testing sample #39: train acc is: 85.0/99\n",
      "Testing sample #40: train acc is: 84.0/99\n",
      "Testing sample #41: train acc is: 94.0/99\n",
      "Testing sample #42: train acc is: 81.0/99\n",
      "Testing sample #43: train acc is: 93.0/99\n",
      "Testing sample #44: train acc is: 83.0/99\n",
      "Testing sample #45: train acc is: 85.0/99\n",
      "Testing sample #46: train acc is: 83.0/99\n",
      "Testing sample #47: train acc is: 85.0/99\n",
      "Testing sample #48: train acc is: 84.0/99\n",
      "Testing sample #49: train acc is: 83.0/99\n",
      "Testing sample #50: train acc is: 93.0/99\n",
      "Testing sample #51: train acc is: 83.0/99\n",
      "Testing sample #52: train acc is: 86.0/99\n",
      "Testing sample #53: train acc is: 84.0/99\n",
      "Testing sample #54: train acc is: 86.0/99\n",
      "Testing sample #55: train acc is: 91.0/99\n",
      "Testing sample #56: train acc is: 84.0/99\n",
      "Testing sample #57: train acc is: 87.0/99\n",
      "Testing sample #58: train acc is: 95.0/99\n",
      "Testing sample #59: train acc is: 83.0/99\n",
      "Testing sample #60: train acc is: 83.0/99\n",
      "Testing sample #61: train acc is: 83.0/99\n",
      "Testing sample #62: train acc is: 82.0/99\n",
      "Testing sample #63: train acc is: 82.0/99\n",
      "Testing sample #64: train acc is: 95.0/99\n",
      "Testing sample #65: train acc is: 92.0/99\n",
      "Testing sample #66: train acc is: 86.0/99\n",
      "Testing sample #67: train acc is: 89.0/99\n",
      "Testing sample #68: train acc is: 84.0/99\n",
      "Testing sample #69: train acc is: 86.0/99\n",
      "Testing sample #70: train acc is: 82.0/99\n",
      "Testing sample #71: train acc is: 83.0/99\n",
      "Testing sample #72: train acc is: 87.0/99\n",
      "Testing sample #73: train acc is: 93.0/99\n",
      "Testing sample #74: train acc is: 81.0/99\n",
      "Testing sample #75: train acc is: 91.0/99\n",
      "Testing sample #76: train acc is: 85.0/99\n",
      "Testing sample #77: train acc is: 89.0/99\n",
      "Testing sample #78: train acc is: 95.0/99\n",
      "Testing sample #79: train acc is: 96.0/99\n",
      "Testing sample #80: train acc is: 93.0/99\n",
      "Testing sample #81: train acc is: 83.0/99\n",
      "Testing sample #82: train acc is: 90.0/99\n",
      "Testing sample #83: train acc is: 91.0/99\n",
      "Testing sample #84: train acc is: 85.0/99\n",
      "Testing sample #85: train acc is: 85.0/99\n",
      "Testing sample #86: train acc is: 84.0/99\n",
      "Testing sample #87: train acc is: 83.0/99\n",
      "Testing sample #88: train acc is: 84.0/99\n",
      "Testing sample #89: train acc is: 82.0/99\n",
      "Testing sample #90: train acc is: 85.0/99\n",
      "Testing sample #91: train acc is: 88.0/99\n",
      "Testing sample #92: train acc is: 83.0/99\n",
      "Testing sample #93: train acc is: 83.0/99\n",
      "Testing sample #94: train acc is: 86.0/99\n",
      "Testing sample #95: train acc is: 87.0/99\n",
      "Testing sample #96: train acc is: 83.0/99\n",
      "Testing sample #97: train acc is: 84.0/99\n",
      "Testing sample #98: train acc is: 83.0/99\n",
      "Testing sample #99: train acc is: 82.0/99\n",
      "Finished: test acc is: 55.0/100\n"
     ]
    }
   ],
   "source": [
    "num_correct_predictions = 0\n",
    "num_samples = 100\n",
    "\n",
    "for idx in tqdm(range(len(signature_data))):\n",
    "    train_data = signature_data[:idx] + signature_data[idx+1:]\n",
    "    model = SequenceClassifier(360, 20, 1, 2, device=device).to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate) \n",
    "    test_sample = signature_data[idx]\n",
    "    train_loader = torch.utils.data.DataLoader(train_data, batch_size=4, num_workers=8, shuffle=True, pin_memory=True)\n",
    "    for epoch in range(num_epochs):\n",
    "        data_loop = train_loader\n",
    "        for data in data_loop:\n",
    "            \n",
    "            x, y = data\n",
    "            x = x.to(device).squeeze(1)\n",
    "            y = y.to(device).squeeze(1).long()  \n",
    "                    \n",
    "            predictions = model(x)\n",
    "            loss = criterion(predictions, y)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "                \n",
    "        total = 0\n",
    "        num_corrects = 0\n",
    "        \n",
    "    for data in train_loader:\n",
    "        \n",
    "        x, y = data\n",
    "        x = x.to(device).squeeze(1)\n",
    "        y = y.to(device).squeeze(1).long()  \n",
    "        model.eval()\n",
    "        \n",
    "        with torch.no_grad():\n",
    "        \n",
    "            predictions = model(x)\n",
    "            _, predictions = predictions.max(1)\n",
    "            num_corrects += (predictions == y).float().sum()\n",
    "            total += predictions.size(0)\n",
    "        \n",
    "        model.train()\n",
    "        \n",
    "    print(f\"Testing sample #{idx}: train acc is: {num_corrects}/{total}\")\n",
    "                        \n",
    "    x, y = test_sample\n",
    "    x = x.to(device).unsqueeze(0)\n",
    "    y = y.to(device).unsqueeze(0).long()  \n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "\n",
    "        predictions = model(x)\n",
    "        _, predictions = predictions.max(1)\n",
    "        num_correct_predictions += (predictions == y).float().sum()\n",
    "        \n",
    "    model.train()  \n",
    "        \n",
    "print(f\"Finished: test acc is: {num_correct_predictions}/{num_samples}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished: test acc is: 50.0/100%\n"
     ]
    }
   ],
   "source": [
    "print(f\"Finished: test acc is: {num_correct_predictions}/{num_samples}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
